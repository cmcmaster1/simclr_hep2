{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/spijkervet/SimCLR.git\n",
    "%cd SimCLR\n",
    "!mkdir -p logs && cd logs && wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar && cd ../\n",
    "!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "!pip install  pyyaml --upgrade\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model import save_model, load_optimizer\n",
    "from modules import SimCLR, get_resnet, NT_Xent\n",
    "from modules.transformations import TransformsSimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 64\n",
    "args.dataset = \"local\" # make sure to check this with the (pre-)trained checkpoint\n",
    "args.resnet = \"resnet50\" # make sure to check this with the (pre-)trained checkpoint\n",
    "args.model_path = \"logs\"\n",
    "args.epoch_num = 200\n",
    "args.logistic_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "file_id=\"1nb__5N4HRDEJt-SILcyUBjPXcXqb2jPT\"\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "gdown.download(url, f'{args.model_path}/checkpoint_200.tar', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': torchvision.datasets.ImageFolder(\n",
    "        'kneeKL224/train', \n",
    "        transform=TransformsSimCLR(size=args.image_size).train_transform\n",
    "        ),\n",
    "    'validation': torchvision.datasets.ImageFolder(\n",
    "        'kneeKL224/val', \n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform\n",
    "        )\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(\n",
    "        image_datasets['train'], \n",
    "        batch_size=args.logistic_batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=args.workers),\n",
    "    'validation': DataLoader(\n",
    "        image_datasets['validation'], \n",
    "        batch_size=args.logistic_batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=args.workers)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_resnet(args.resnet, pretrained=False) # don't load a pre-trained model from PyTorch repo\n",
    "n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "# load pre-trained model from checkpoint\n",
    "simclr_model = SimCLR(args, encoder, n_features)\n",
    "model_fp = os.path.join(\n",
    "    args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num)\n",
    ")\n",
    "simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "simclr_model = simclr_model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_dim = simclr_model.projector[0].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_model.projector = nn.Sequential(\n",
    "    nn.Linear(output_feature_dim, output_feature_dim // 2),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(output_feature_dim // 2, 5),\n",
    "    nn.LogSoftmax(dim=1)).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            valid_acc = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                correct_tensor = preds.eq(labels.data.view_as(preds))\n",
    "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "                valid_acc += accuracy.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = valid_acc / len(image_datasets[phase])\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist = [\n",
    "        {'params': encoder.encoder[7].parameters(), 'lr': 1e-5},\n",
    "        {'params': encoder.projetion.parameters(), 'lr': 5e-3}\n",
    "        ]\n",
    "optimizer_ft = optim.Adam(plist, lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "model_ft = train_model(encoder,\n",
    "                       criterion,\n",
    "                       optimizer_ft,\n",
    "                       lr_sch,\n",
    "                       num_epochs=3)\n",
    "\n",
    "torch.save(model_ft.state_dict(), \"model.bin\")"
   ]
  }
 ]
}